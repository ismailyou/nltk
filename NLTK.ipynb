{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK - Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NLTK</b> is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries.\n",
    "\n",
    "URL : https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = \"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowedrational numbers,irrational numbers, geometrical magnitudes, etc., to all be treated as \\\"algebraic objects\\\". It gave mathematics a whole new development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itselfin a way which had not happened before.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowedrational numbers,irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itselfin a way which had not happened before.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_text =\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي وهي بدايات الجبر, ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة, فقد كانت خطوة نورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة, الجبر کان نظرية موحدة تتيح الأعداد الكسرية والأعداد اللا كسرية, والمقادير الهندسية وغيرها, أن تتعامل على أنها أجسام جبرية, وأعطت الرياضيات ككل مسارا جديدا للتطور بمفهوم أوسع بكثير من الذي كان موجودا من قبل, وقم وسيلة للتنمية في هذا الموضوع مستقبلا. وجانب آخر مهم لإدخال أفكار الجبر وهو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي وهي بدايات الجبر, ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة, فقد كانت خطوة نورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة, الجبر کان نظرية موحدة تتيح الأعداد الكسرية والأعداد اللا كسرية, والمقادير الهندسية وغيرها, أن تتعامل على أنها أجسام جبرية, وأعطت الرياضيات ككل مسارا جديدا للتطور بمفهوم أوسع بكثير من الذي كان موجودا من قبل, وقم وسيلة للتنمية في هذا الموضوع مستقبلا. وجانب آخر مهم لإدخال أفكار الجبر وهو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text= english_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate Ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english_text_clear = ''.join([x for x in english_text if x not in string.punctuation])\n",
    "#arabic_text_clear = ''.join([x for x in arabic_text if x not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perhaps one of the most significant advances made by arabic mathematics began at this time with the work of alkhwarizmi namely the beginnings of algebra it is important to understand just how significant this new idea was it was a revolutionary move away from the greek concept of mathematics which was essentially geometry algebra was a unifying theory which allowedrational numbersirrational numbers geometrical magnitudes etc to all be treated as algebraic objects it gave mathematics a whole new development path so much broader in concept to that which had existed before and provided a vehicle for future development of the subject another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itselfin a way which had not happened before\n",
      "ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و المقادير الهندسية و غيرها، أن تتعامل على أنها أجسام جبرية، و أعطت الرياضيات ككل مسارا جديدا للتطور بمفهوم أوسع بكثير من الذي كان موجودا من قبل، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(english_text_clear)\n",
    "#print(arabic_text_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokinization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = word_tokenize(english_text)\n",
    "ar_words = nltk.word_tokenize(arabic_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using word_tokenize() to split up our text into words:<br>\n",
    "\n",
    "       - Perhaps \n",
    "       - one \n",
    "       - of \n",
    "       - the \n",
    "       - most\n",
    "\n",
    "But NLTK were also considered these strings to be words:\n",
    "\n",
    "       - ','\n",
    "       - '.'\n",
    "\n",
    "<b>Arabic Text Also The same Things</b>\n",
    "    e.g :\n",
    "    \n",
    "    \n",
    "        \n",
    "         'أحد',\n",
    "         'أهم',\n",
    "         'التطورات',\n",
    "         'التي',\n",
    "         'قامت',\n",
    "         'بها',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing by sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sent = sent_tokenize(english_text)\n",
    "ar_sent = sent_tokenize(arabic_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>sent_tokenize()</b> splite the text into sentences :\n",
    "\n",
    "        - 'perhaps one of the most significant advances made by arabic mathematics began at this time with the work of al-khwarizmi, namely the beginnings of algebra.'\n",
    "        - 'it is important to understand just how significant this new idea was.'\n",
    "Same Thing In Arabic Text :\n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are words that we want to ignore, so we filter them out of our text when we’re processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BASH_TOOR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_eng = set(stopwords.words(\"english\"))\n",
    "stop_words_ar = set(stopwords.words(\"arabic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ربما',\n",
       " 'كانت',\n",
       " 'أحد',\n",
       " 'أهم',\n",
       " 'التطورات',\n",
       " 'قامت',\n",
       " 'الرياضيات',\n",
       " 'العربية',\n",
       " 'بدأت',\n",
       " 'الوقت',\n",
       " 'بعمل',\n",
       " 'الخوارزمي',\n",
       " 'وهي',\n",
       " 'بدايات',\n",
       " 'الجبر',\n",
       " ',',\n",
       " 'المهم',\n",
       " 'فهم',\n",
       " 'كانت',\n",
       " 'الفكرة',\n",
       " 'الجديدة',\n",
       " 'مهمة',\n",
       " ',',\n",
       " 'فقد',\n",
       " 'كانت',\n",
       " 'خطوة',\n",
       " 'نورية',\n",
       " 'بعيدا',\n",
       " 'المفهوم',\n",
       " 'اليوناني',\n",
       " 'للرياضيات',\n",
       " 'جوهرها',\n",
       " 'هندسة',\n",
       " ',',\n",
       " 'الجبر',\n",
       " 'کان',\n",
       " 'نظرية',\n",
       " 'موحدة',\n",
       " 'تتيح',\n",
       " 'الأعداد',\n",
       " 'الكسرية',\n",
       " 'والأعداد',\n",
       " 'اللا',\n",
       " 'كسرية',\n",
       " ',',\n",
       " 'والمقادير',\n",
       " 'الهندسية',\n",
       " 'وغيرها',\n",
       " ',',\n",
       " 'تتعامل',\n",
       " 'أنها',\n",
       " 'أجسام',\n",
       " 'جبرية',\n",
       " ',',\n",
       " 'وأعطت',\n",
       " 'الرياضيات',\n",
       " 'ككل',\n",
       " 'مسارا',\n",
       " 'جديدا',\n",
       " 'للتطور',\n",
       " 'بمفهوم',\n",
       " 'أوسع',\n",
       " 'بكثير',\n",
       " 'كان',\n",
       " 'موجودا',\n",
       " 'قبل',\n",
       " ',',\n",
       " 'وقم',\n",
       " 'وسيلة',\n",
       " 'للتنمية',\n",
       " 'الموضوع',\n",
       " 'مستقبلا',\n",
       " '.',\n",
       " 'وجانب',\n",
       " 'آخر',\n",
       " 'مهم',\n",
       " 'لإدخال',\n",
       " 'أفكار',\n",
       " 'الجبر',\n",
       " 'أنه',\n",
       " 'سمح',\n",
       " 'بتطبيق',\n",
       " 'الرياضيات',\n",
       " 'نفسها',\n",
       " 'بطريقة',\n",
       " 'تحدث',\n",
       " 'قبل']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_english_text = []\n",
    "for word in eng_words:\n",
    "    if word.casefold() not in stop_words_eng:\n",
    "        filter_english_text.append(word)\n",
    "\n",
    "# Arabic Text using List Comprehension\n",
    "filter_arabic_text = [\n",
    "    word for word in ar_words if word not in stop_words_ar\n",
    "]\n",
    "\n",
    "filter_arabic_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming  English Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>reduce words to their root</b>, which is the core part of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate PorterStemmer Object\n",
    "\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perhap',\n",
       " 'one',\n",
       " 'signific',\n",
       " 'advanc',\n",
       " 'made',\n",
       " 'arab',\n",
       " 'mathemat',\n",
       " 'began',\n",
       " 'time',\n",
       " 'work',\n",
       " 'al-khwarizmi',\n",
       " ',',\n",
       " 'name',\n",
       " 'begin',\n",
       " 'algebra',\n",
       " '.',\n",
       " 'import',\n",
       " 'understand',\n",
       " 'signific',\n",
       " 'new',\n",
       " 'idea',\n",
       " '.',\n",
       " 'revolutionari',\n",
       " 'move',\n",
       " 'away',\n",
       " 'greek',\n",
       " 'concept',\n",
       " 'mathemat',\n",
       " 'essenti',\n",
       " 'geometri',\n",
       " '.',\n",
       " 'algebra',\n",
       " 'unifi',\n",
       " 'theori',\n",
       " 'allowedr',\n",
       " 'number',\n",
       " ',',\n",
       " 'irrat',\n",
       " 'number',\n",
       " ',',\n",
       " 'geometr',\n",
       " 'magnitud',\n",
       " ',',\n",
       " 'etc.',\n",
       " ',',\n",
       " 'treat',\n",
       " '``',\n",
       " 'algebra',\n",
       " 'object',\n",
       " \"''\",\n",
       " '.',\n",
       " 'gave',\n",
       " 'mathemat',\n",
       " 'whole',\n",
       " 'new',\n",
       " 'develop',\n",
       " 'path',\n",
       " 'much',\n",
       " 'broader',\n",
       " 'concept',\n",
       " 'exist',\n",
       " ',',\n",
       " 'provid',\n",
       " 'vehicl',\n",
       " 'futur',\n",
       " 'develop',\n",
       " 'subject',\n",
       " '.',\n",
       " 'anoth',\n",
       " 'import',\n",
       " 'aspect',\n",
       " 'introduct',\n",
       " 'algebra',\n",
       " 'idea',\n",
       " 'allow',\n",
       " 'mathemat',\n",
       " 'appli',\n",
       " 'itselfin',\n",
       " 'way',\n",
       " 'happen',\n",
       " '.']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_words_stem = [stem.stem(word) for word in filter_english_text]\n",
    "english_words_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming  Arabic Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowballstemmer import stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ربم',\n",
       " 'كان',\n",
       " 'احد',\n",
       " 'اهم',\n",
       " 'تطور',\n",
       " 'قام',\n",
       " 'رياض',\n",
       " 'عرب',\n",
       " 'بدء',\n",
       " 'وقت',\n",
       " 'عمل',\n",
       " 'خوارزم',\n",
       " 'وه',\n",
       " 'دايا',\n",
       " 'جبر',\n",
       " ',',\n",
       " 'مهم',\n",
       " 'فهم',\n",
       " 'كان',\n",
       " 'فكر',\n",
       " 'جديد',\n",
       " 'مهم',\n",
       " ',',\n",
       " 'فقد',\n",
       " 'كان',\n",
       " 'خطو',\n",
       " 'نور',\n",
       " 'عيد',\n",
       " 'مفهوم',\n",
       " 'يونان',\n",
       " 'رياض',\n",
       " 'جوهر',\n",
       " 'هندس',\n",
       " ',',\n",
       " 'جبر',\n",
       " 'کان',\n",
       " 'نظر',\n",
       " 'موحد',\n",
       " 'تتيح',\n",
       " 'اعداد',\n",
       " 'كسر',\n",
       " 'والاعداد',\n",
       " 'اللا',\n",
       " 'كسر',\n",
       " ',',\n",
       " 'والمقادير',\n",
       " 'هندس',\n",
       " 'غير',\n",
       " ',',\n",
       " 'تتعامل',\n",
       " 'انه',\n",
       " 'اجسام',\n",
       " 'جبر',\n",
       " ',',\n",
       " 'اعط',\n",
       " 'رياض',\n",
       " 'ككل',\n",
       " 'مسار',\n",
       " 'جديد',\n",
       " 'تطور',\n",
       " 'مفهوم',\n",
       " 'اوسع',\n",
       " 'كثير',\n",
       " 'كان',\n",
       " 'موجود',\n",
       " 'قبل',\n",
       " ',',\n",
       " 'وقم',\n",
       " 'سيل',\n",
       " 'تنم',\n",
       " 'موضوع',\n",
       " 'مستقبل',\n",
       " '.',\n",
       " 'جانب',\n",
       " 'اخر',\n",
       " 'مهم',\n",
       " 'لادخال',\n",
       " 'افكار',\n",
       " 'جبر',\n",
       " 'انه',\n",
       " 'سمح',\n",
       " 'تطبيق',\n",
       " 'رياض',\n",
       " 'نفس',\n",
       " 'طريق',\n",
       " 'تحدث',\n",
       " 'قبل']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_stemmer = stemmer(\"arabic\")\n",
    "\n",
    "arabic_words_stem = [ar_stemmer.stemWord(ar_word) for ar_word in filter_arabic_text]\n",
    "arabic_words_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Taking a look at the result , some of the output is difinitvely correct e.g:\n",
    "\n",
    "      \n",
    "      -  التطورات -  تطور\n",
    "      -  عدد  -  الأعداد \n",
    "      - للتطور -   تطور \n",
    "\n",
    "But in the other hand the Stemmer give us a wrong result :\n",
    "\n",
    "        - ربم\n",
    "        - رياض\n",
    "        - خطو\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Understemming</b> happens when two related words should be reduced to the same stem but aren’t. This is a false negative.\n",
    "<b>Overstemming</b> happens when two unrelated words are reduced to the same stem even though they shouldn’t be. This is a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Parts of Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging, is the task of labeling the words in your text according to their part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pos_tag = nltk.pos_tag(eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_pos_tag = nltk.pos_tag(ar_words) \n",
    "#like every one said its not workin in the arabic lang (NNP for all tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lemma is a word that represents a whole group of words, and that group of words is called a lexeme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in eng_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perhaps',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'advance',\n",
       " 'made',\n",
       " 'by',\n",
       " 'arabic',\n",
       " 'mathematics',\n",
       " 'began',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'with',\n",
       " 'the',\n",
       " 'work',\n",
       " 'of',\n",
       " 'al-khwarizmi',\n",
       " ',',\n",
       " 'namely',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'algebra',\n",
       " '.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'important',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'just',\n",
       " 'how',\n",
       " 'significant',\n",
       " 'this',\n",
       " 'new',\n",
       " 'idea',\n",
       " 'wa',\n",
       " '.',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'revolutionary',\n",
       " 'move',\n",
       " 'away',\n",
       " 'from',\n",
       " 'the',\n",
       " 'greek',\n",
       " 'concept',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " 'which',\n",
       " 'wa',\n",
       " 'essentially',\n",
       " 'geometry',\n",
       " '.',\n",
       " 'algebra',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'unifying',\n",
       " 'theory',\n",
       " 'which',\n",
       " 'allowedrational',\n",
       " 'number',\n",
       " ',',\n",
       " 'irrational',\n",
       " 'number',\n",
       " ',',\n",
       " 'geometrical',\n",
       " 'magnitude',\n",
       " ',',\n",
       " 'etc.',\n",
       " ',',\n",
       " 'to',\n",
       " 'all',\n",
       " 'be',\n",
       " 'treated',\n",
       " 'a',\n",
       " '``',\n",
       " 'algebraic',\n",
       " 'object',\n",
       " \"''\",\n",
       " '.',\n",
       " 'it',\n",
       " 'gave',\n",
       " 'mathematics',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'new',\n",
       " 'development',\n",
       " 'path',\n",
       " 'so',\n",
       " 'much',\n",
       " 'broader',\n",
       " 'in',\n",
       " 'concept',\n",
       " 'to',\n",
       " 'that',\n",
       " 'which',\n",
       " 'had',\n",
       " 'existed',\n",
       " 'before',\n",
       " ',',\n",
       " 'and',\n",
       " 'provided',\n",
       " 'a',\n",
       " 'vehicle',\n",
       " 'for',\n",
       " 'future',\n",
       " 'development',\n",
       " 'of',\n",
       " 'the',\n",
       " 'subject',\n",
       " '.',\n",
       " 'another',\n",
       " 'important',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'the',\n",
       " 'introduction',\n",
       " 'of',\n",
       " 'algebraic',\n",
       " 'idea',\n",
       " 'wa',\n",
       " 'that',\n",
       " 'it',\n",
       " 'allowed',\n",
       " 'mathematics',\n",
       " 'to',\n",
       " 'be',\n",
       " 'applied',\n",
       " 'to',\n",
       " 'itselfin',\n",
       " 'a',\n",
       " 'way',\n",
       " 'which',\n",
       " 'had',\n",
       " 'not',\n",
       " 'happened',\n",
       " 'before',\n",
       " '.']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While <b>tokenizing</b> allows you to identify words and sentences, <b>chunking</b> allows you to identify phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NP</b> stands for noun phrase\n",
    "       \n",
    "        Start with an optional (?) determiner ('DT')\n",
    "        Can have any number (*) of adjectives (JJ)\n",
    "        End with a noun (<NN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ghostscript\n",
      "  Downloading ghostscript-0.7-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: setuptools>=38.6.0 in c:\\users\\bash_toor\\anaconda3\\lib\\site-packages (from ghostscript) (50.3.1.post20201107)\n",
      "Installing collected packages: ghostscript\n",
      "Successfully installed ghostscript-0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ghostscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can not find Ghostscript DLL in registry",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-9c2461507f92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mghostscript\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mghostscript\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ghostscript\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;31m# :todo: remove, debugging only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_gsprint\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ghostscript\\_gsprint.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[0mlibgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__win32_finddll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlibgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Can not find Ghostscript DLL in registry'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[0mlibgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can not find Ghostscript DLL in registry"
     ]
    }
   ],
   "source": [
    "import ghostscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m                     [\n\u001b[1;32m--> 798\u001b[1;33m                         find_binary(\n\u001b[0m\u001b[0;32m    799\u001b[0m                             \u001b[1;34m\"gs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    687\u001b[0m ):\n\u001b[1;32m--> 688\u001b[1;33m     return next(\n\u001b[0m\u001b[0;32m    689\u001b[0m         find_binary_iter(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m     for file in find_file_iter(\n\u001b[0m\u001b[0;32m    674\u001b[0m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"=\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n%s\\n%s\\n%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 )\n\u001b[0;32m    816\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('perhaps', 'RB'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('significant', 'JJ'), ('advances', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('arabic', 'JJ'), ('mathematics', 'NNS'), ('began', 'VBD'), ('at', 'IN'), Tree('NP', [('this', 'DT'), ('time', 'NN')]), ('with', 'IN'), Tree('NP', [('the', 'DT'), ('work', 'NN')]), ('of', 'IN'), ('al-khwarizmi', 'JJ'), (',', ','), ('namely', 'RB'), ('the', 'DT'), ('beginnings', 'NNS'), ('of', 'IN'), Tree('NP', [('algebra', 'NN')]), ('.', '.'), ('it', 'PRP'), ('is', 'VBZ'), ('important', 'JJ'), ('to', 'TO'), ('understand', 'VB'), ('just', 'RB'), ('how', 'WRB'), ('significant', 'JJ'), Tree('NP', [('this', 'DT'), ('new', 'JJ'), ('idea', 'NN')]), ('was', 'VBD'), ('.', '.'), ('it', 'PRP'), ('was', 'VBD'), Tree('NP', [('a', 'DT'), ('revolutionary', 'JJ'), ('move', 'NN')]), ('away', 'RB'), ('from', 'IN'), Tree('NP', [('the', 'DT'), ('greek', 'JJ'), ('concept', 'NN')]), ('of', 'IN'), ('mathematics', 'NNS'), ('which', 'WDT'), ('was', 'VBD'), ('essentially', 'RB'), ('geometry', 'JJ'), ('.', '.'), Tree('NP', [('algebra', 'NN')]), ('was', 'VBD'), Tree('NP', [('a', 'DT'), ('unifying', 'JJ'), ('theory', 'NN')]), ('which', 'WDT'), ('allowedrational', 'JJ'), ('numbers', 'NNS'), (',', ','), ('irrational', 'JJ'), ('numbers', 'NNS'), (',', ','), ('geometrical', 'JJ'), ('magnitudes', 'NNS'), (',', ','), Tree('NP', [('etc.', 'NN')]), (',', ','), ('to', 'TO'), ('all', 'DT'), ('be', 'VB'), ('treated', 'VBN'), ('as', 'IN'), ('``', '``'), ('algebraic', 'JJ'), ('objects', 'NNS'), (\"''\", \"''\"), ('.', '.'), ('it', 'PRP'), ('gave', 'VBD'), ('mathematics', 'NNS'), Tree('NP', [('a', 'DT'), ('whole', 'JJ'), ('new', 'JJ'), ('development', 'NN')]), Tree('NP', [('path', 'NN')]), ('so', 'RB'), ('much', 'JJ'), ('broader', 'JJR'), ('in', 'IN'), Tree('NP', [('concept', 'NN')]), ('to', 'TO'), ('that', 'DT'), ('which', 'WDT'), ('had', 'VBD'), ('existed', 'VBN'), ('before', 'IN'), (',', ','), ('and', 'CC'), ('provided', 'VBD'), Tree('NP', [('a', 'DT'), ('vehicle', 'NN')]), ('for', 'IN'), Tree('NP', [('future', 'JJ'), ('development', 'NN')]), ('of', 'IN'), Tree('NP', [('the', 'DT'), ('subject', 'NN')]), ('.', '.'), Tree('NP', [('another', 'DT'), ('important', 'JJ'), ('aspect', 'NN')]), ('of', 'IN'), Tree('NP', [('the', 'DT'), ('introduction', 'NN')]), ('of', 'IN'), ('algebraic', 'JJ'), ('ideas', 'NNS'), ('was', 'VBD'), ('that', 'IN'), ('it', 'PRP'), ('allowed', 'VBD'), ('mathematics', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('applied', 'VBN'), ('to', 'TO'), ('itselfin', 'VB'), Tree('NP', [('a', 'DT'), ('way', 'NN')]), ('which', 'WDT'), ('had', 'VBD'), ('not', 'RB'), ('happened', 'VBN'), ('before', 'IN'), ('.', '.')])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_parser.parse(eng_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.5\n",
      "IPython version      : 7.19.0\n",
      "\n",
      "nltk: 3.5\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 42 Stepping 7, GenuineIntel\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk: 3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
